import ast
import re
from typing import List, Dict, Any, Optional, Set, Tuple
from pathlib import Path

class FastAPIEndpointAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è FastAPI —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤ –≤ Python —Ñ–∞–π–ª–∞—Ö
    """
    
    def __init__(self):
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ FastAPI –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–æ–≤
        self.route_decorators = {
            'get': re.compile(r'@(?:app|router)\.get\((.*?)\)'),
            'post': re.compile(r'@(?:app|router)\.post\((.*?)\)'),
            'put': re.compile(r'@(?:app|router)\.put\((.*?)\)'),
            'delete': re.compile(r'@(?:app|router)\.delete\((.*?)\)'),
            'patch': re.compile(r'@(?:app|router)\.patch\((.*?)\)'),
            'options': re.compile(r'@(?:app|router)\.options\((.*?)\)'),
            'head': re.compile(r'@(?:app|router)\.head\((.*?)\)'),
            'api_route': re.compile(r'@(?:app|router)\.api_route\((.*?)\)'),
        }
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        self.dependency_pattern = re.compile(r'Depends\((.*?)\)')
        self.router_include_pattern = re.compile(r'(?:app|router)\.include_router\((.*?)\)')
    
    def analyze_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –Ω–∞ –Ω–∞–ª–∏—á–∏–µ FastAPI —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
        
        Args:
            file_path: –ü—É—Ç—å –∫ Python —Ñ–∞–π–ª—É
            
        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤ —Å –∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                tree = ast.parse(content, filename=str(file_path))
            
            endpoints = []
            # –ü–æ–∏—Å–∫ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–æ–≤ –Ω–∞ —É—Ä–æ–≤–Ω–µ –º–æ–¥—É–ª—è
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    endpoint = self._analyze_function_as_endpoint(node, content)
                    if endpoint:
                        endpoint['file'] = str(file_path)
                        endpoints.append(endpoint)
            
            # –ü–æ–∏—Å–∫ –≤–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ä–æ—É—Ç–µ—Ä–æ–≤
            included_routers = self._find_included_routers(tree, content)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            result = {
                'endpoints': endpoints,
                'included_routers': included_routers,
                'file_path': str(file_path)
            }
            
            return endpoints
            
        except (SyntaxError, UnicodeDecodeError, FileNotFoundError) as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ FastAPI —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤ –≤ {file_path}: {e}")
            return []
    
    def _analyze_function_as_endpoint(self, node: ast.FunctionDef, content: str) -> Optional[Dict[str, Any]]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –Ω–∞–ª–∏—á–∏—è FastAPI –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–æ–≤
        """
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞
        func_text = ast.get_source_segment(content, node)
        if not func_text:
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä
        for decorator in node.decorator_list:
            dec_text = ast.get_source_segment(content, decorator)
            if not dec_text:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ FastAPI –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–æ–≤
            for method, pattern in self.route_decorators.items():
                match = pattern.search(dec_text)
                if match:
                    path = match.group(1).strip('"\'')
                    return self._extract_endpoint_details(
                        node, func_text, method, path, dec_text
                    )
        
        return None
    
    def _extract_endpoint_details(self, node: ast.FunctionDef, func_text: str, 
                                 method: str, path: str, decorator_text: str) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ—Ç–∞–ª–∏ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞
        """
        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        endpoint = {
            'name': node.name,
            'method': method.upper(),
            'path': path,
            'line_number': node.lineno,
            'summary': self._extract_docstring_summary(node),
            'dependencies': [],
            'parameters': [],
            'response_model': None,
            'status_code': None,
            'tags': [],
            'deprecated': False,
            'decorator_raw': decorator_text.strip()
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self._analyze_decorator_arguments(decorator_text, endpoint)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ—É–Ω–∫—Ü–∏–∏
        self._analyze_function_parameters(node, endpoint)
        
        return endpoint
    
    def _analyze_decorator_arguments(self, decorator_text: str, endpoint: Dict[str, Any]):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        """
        # –ü–æ–∏—Å–∫ —Ç–µ–≥–æ–≤
        tags_match = re.search(r'tags\s*=\s*(\[[^\]]*\])', decorator_text)
        if tags_match:
            try:
                tags_str = tags_match.group(1)
                # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Ç–µ–≥–æ–≤
                tags = [tag.strip('"\' ') for tag in tags_str.strip('[]').split(',') if tag.strip()]
                endpoint['tags'] = tags
            except:
                pass
        
        # –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç—É—Å –∫–æ–¥–∞
        status_match = re.search(r'status_code\s*=\s*(\d+)', decorator_text)
        if status_match:
            try:
                endpoint['status_code'] = int(status_match.group(1))
            except:
                pass
        
        # –ü–æ–∏—Å–∫ deprecated
        if 'deprecated=True' in decorator_text:
            endpoint['deprecated'] = True
        
        # –ü–æ–∏—Å–∫ response_model
        response_match = re.search(r'response_model\s*=\s*([^,\)]+)', decorator_text)
        if response_match:
            endpoint['response_model'] = response_match.group(1).strip()
    
    def _analyze_function_parameters(self, node: ast.FunctionDef, endpoint: Dict[str, Any]):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –ø—É—Ç–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        """
        for arg in node.args.args:
            param_info = {
                'name': arg.arg,
                'annotation': None,
                'default': None,
                'type': 'regular'  # regular, path, dependency
            }
            
            # –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è —Ç–∏–ø–∞
            if arg.annotation:
                try:
                    param_info['annotation'] = ast.unparse(arg.annotation)
                except:
                    param_info['annotation'] = str(arg.annotation)
            
            # –ü–æ–∏—Å–∫ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if node.args.defaults:
                default_idx = len(node.args.args) - len(node.args.defaults) + node.args.args.index(arg)
                if default_idx >= 0 and default_idx < len(node.args.defaults):
                    try:
                        default_val = node.args.defaults[default_idx]
                        param_info['default'] = ast.unparse(default_val)
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å
                        if isinstance(default_val, ast.Call) and hasattr(default_val.func, 'id'):
                            if default_val.func.id == 'Depends':
                                param_info['type'] = 'dependency'
                                dep_match = self.dependency_pattern.search(param_info['default'])
                                if dep_match:
                                    param_info['dependency_name'] = dep_match.group(1).strip()
                    except:
                        pass
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä (–µ—Å–ª–∏ –µ—Å—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è Path)
            if param_info['annotation'] and 'Path' in param_info['annotation']:
                param_info['type'] = 'path'
            
            endpoint['parameters'].append(param_info)
    
    def _find_included_routers(self, tree: ast.AST, content: str) -> List[Dict[str, Any]]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –≤–∫–ª—é—á–µ–Ω–Ω—ã–µ —Ä–æ—É—Ç–µ—Ä—ã –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏
        """
        routers = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                try:
                    call_text = ast.get_source_segment(content, node)
                    if call_text and ('.include_router(' in call_text or '.include_router(' in call_text.lower()):
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—ã–∑–æ–≤–∞
                        router_match = self.router_include_pattern.search(call_text)
                        if router_match:
                            router_info = {
                                'raw_call': call_text.strip(),
                                'line_number': node.lineno
                            }
                            
                            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–º—è —Ä–æ—É—Ç–µ—Ä–∞
                            router_name = router_match.group(1).split(',')[0].strip()
                            router_info['router_name'] = router_name
                            
                            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –ø—Ä–µ—Ñ–∏–∫—Å
                            prefix_match = re.search(r'prefix\s*=\s*(.*?)(?:,|\))', call_text)
                            if prefix_match:
                                router_info['prefix'] = prefix_match.group(1).strip('"\'')
                            
                            routers.append(router_info)
                except:
                    continue
        
        return routers
    
    def _extract_docstring_summary(self, node: ast.FunctionDef) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ docstring —Ñ—É–Ω–∫—Ü–∏–∏
        """
        if ast.get_docstring(node):
            doc = ast.get_docstring(node)
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∏–ª–∏ –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
            summary = doc.strip().split('\n')[0]
            if len(summary) > 100:
                summary = summary[:97] + '...'
            return summary
        return ''
    
    def analyze_project(self, project_path: Path, file_patterns: List[str] = None) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ FastAPI —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
        
        Args:
            project_path: –ö–æ—Ä–Ω–µ–≤–æ–π –ø—É—Ç—å –ø—Ä–æ–µ–∫—Ç–∞
            file_patterns: –®–∞–±–ª–æ–Ω—ã —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ['*api*.py', '*router*.py'])
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        if file_patterns is None:
            file_patterns = ['*.py']
        
        endpoints_by_file = {}
        all_endpoints = []
        router_includes = []
        
        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º Python —Ñ–∞–π–ª–∞–º
        for pattern in file_patterns:
            for file_path in project_path.rglob(pattern):
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                if any(excl in str(file_path) for excl in ['tests', 'venv', '.venv', '__pycache__', 'migrations']):
                    continue
                
                endpoints = self.analyze_file(file_path)
                if endpoints:
                    rel_path = file_path.relative_to(project_path).as_posix()
                    endpoints_by_file[rel_path] = endpoints
                    all_endpoints.extend(endpoints)
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = {
            'total_files_analyzed': len(endpoints_by_file),
            'total_endpoints': len(all_endpoints),
            'endpoints_by_method': {},
            'endpoints_by_tag': {}
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ HTTP –º–µ—Ç–æ–¥–∞–º
        for endpoint in all_endpoints:
            method = endpoint['method']
            stats['endpoints_by_method'][method] = stats['endpoints_by_method'].get(method, 0) + 1
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–≥–∞–º
            for tag in endpoint.get('tags', []):
                stats['endpoints_by_tag'][tag] = stats['endpoints_by_tag'].get(tag, 0) + 1
        
        result = {
            'endpoints_by_file': endpoints_by_file,
            'all_endpoints': all_endpoints,
            'router_includes': router_includes,
            'stats': stats,
            'project_path': str(project_path)
        }
        
        return result
    
    def generate_endpoints_report(self, analysis_result: Dict[str, Any]) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ–± —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞—Ö –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        """
        report_lines = []
        report_lines.append("üîç FastAPI Endpoints Analysis Report")
        report_lines.append("=" * 50)
        report_lines.append(f"üìÅ Project: {analysis_result['project_path']}")
        report_lines.append(f"üìä Total files with endpoints: {analysis_result['stats']['total_files_analyzed']}")
        report_lines.append(f"üöÄ Total endpoints: {analysis_result['stats']['total_endpoints']}")
        report_lines.append("")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–µ—Ç–æ–¥–∞–º
        report_lines.append("üìà Endpoints by HTTP Method:")
        for method, count in analysis_result['stats']['endpoints_by_method'].items():
            report_lines.append(f"  {method}: {count}")
        report_lines.append("")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–≥–∞–º
        if analysis_result['stats']['endpoints_by_tag']:
            report_lines.append("üè∑Ô∏è Endpoints by Tag:")
            for tag, count in analysis_result['stats']['endpoints_by_tag'].items():
                report_lines.append(f"  {tag}: {count}")
            report_lines.append("")
        
        # –î–µ—Ç–∞–ª–∏ –ø–æ —Ñ–∞–π–ª–∞–º
        report_lines.append("üìÇ Endpoints by File:")
        for file_path, endpoints in analysis_result['endpoints_by_file'].items():
            report_lines.append(f"\nüìÅ {file_path}:")
            for endpoint in endpoints:
                tags = ", ".join(endpoint.get('tags', [])) if endpoint.get('tags') else "no tags"
                report_lines.append(f"  {endpoint['method']} {endpoint['path']} - {endpoint['name']}")
                if endpoint.get('summary'):
                    report_lines.append(f"    üìù {endpoint['summary']}")
                if tags:
                    report_lines.append(f"    üè∑Ô∏è Tags: {tags}")
                if endpoint.get('dependencies'):
                    deps = ", ".join([d.get('name', '') for d in endpoint['dependencies']])
                    report_lines.append(f"    ‚öôÔ∏è Dependencies: {deps}")
        
        return "\n".join(report_lines)
    
    def generate_endpoints_json(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –æ—Ç—á–µ—Ç –æ–± —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞—Ö
        """
        return {
            'summary': {
                'total_files': analysis_result['stats']['total_files_analyzed'],
                'total_endpoints': analysis_result['stats']['total_endpoints'],
                'methods': analysis_result['stats']['endpoints_by_method'],
                'tags': analysis_result['stats']['endpoints_by_tag']
            },
            'files': analysis_result['endpoints_by_file'],
            'all_endpoints': analysis_result['all_endpoints']
        }
